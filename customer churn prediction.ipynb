{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsaHZUe2z+o//WxX5Lo142"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zL7WQ3-TVB5","executionInfo":{"status":"ok","timestamp":1729181050125,"user_tz":-330,"elapsed":518,"user":{"displayName":"Kalpana K","userId":"07249307408841913099"}},"outputId":"3c8cbd5e-4b6f-4cfa-d5bc-9a24e3d8a320"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik7NnfPnSZQP","executionInfo":{"status":"ok","timestamp":1729181047032,"user_tz":-330,"elapsed":22964,"user":{"displayName":"Kalpana K","userId":"07249307408841913099"}},"outputId":"cbdaace9-2808-472e-f64a-7f3fcb084322"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/Churn_Modelling.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRPNwW4oTXEI","executionInfo":{"status":"ok","timestamp":1729181058318,"user_tz":-330,"elapsed":725,"user":{"displayName":"Kalpana K","userId":"07249307408841913099"}},"outputId":"2dfa5feb-d2df-4a92-cda8-3bc55adb67e0","collapsed":true},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/drive/MyDrive/Churn_Modelling.csv': No such file or directory\n"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Make sure to read the CSV file and create the DataFrame before using it.\n","file_path = \"/content/drive/MyDrive/archive (4)/Churn_Modelling.csv\"\n","\n","# Read the dataset\n","df = pd.read_csv(file_path)\n","\n","# Check if the data loaded properly (this is for validation)\n","print(df.head())\n","\n","# Import machine learning libraries\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Data Preprocessing\n","\n","# Encoding categorical variables (Geography and Gender)\n","label_encoder_geography = LabelEncoder()\n","label_encoder_gender = LabelEncoder()\n","\n","df['Geography'] = label_encoder_geography.fit_transform(df['Geography'])\n","df['Gender'] = label_encoder_gender.fit_transform(df['Gender'])\n","\n","# Features (excluding unnecessary columns like RowNumber, CustomerId, Surname)\n","X = df.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Exited'])\n","y = df['Exited']\n","\n","# Splitting the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Feature scaling (Standardizing the data)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Model 1: Logistic Regression\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","y_pred_log_reg = log_reg.predict(X_test)\n","accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n","print(f'Logistic Regression Accuracy: {accuracy_log_reg}')\n","\n","# Model 2: Random Forest Classifier\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","y_pred_rf = rf_classifier.predict(X_test)\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","print(f'Random Forest Accuracy: {accuracy_rf}')\n","\n","# Model 3: Gradient Boosting Classifier\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(X_train, y_train)\n","y_pred_gb = gb_classifier.predict(X_test)\n","accuracy_gb = accuracy_score(y_test, y_pred_gb)\n","print(f'Gradient Boosting Accuracy: {accuracy_gb}')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aucEUqENiNH","executionInfo":{"status":"ok","timestamp":1729181071929,"user_tz":-330,"elapsed":6437,"user":{"displayName":"Kalpana K","userId":"07249307408841913099"}},"outputId":"85abb0ef-6a22-47be-8b18-945c9f3a8da4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n","0          1    15634602  Hargrave          619    France  Female   42   \n","1          2    15647311      Hill          608     Spain  Female   41   \n","2          3    15619304      Onio          502    France  Female   42   \n","3          4    15701354      Boni          699    France  Female   39   \n","4          5    15737888  Mitchell          850     Spain  Female   43   \n","\n","   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0       2       0.00              1          1               1   \n","1       1   83807.86              1          0               1   \n","2       8  159660.80              3          1               0   \n","3       1       0.00              2          0               0   \n","4       2  125510.82              1          1               1   \n","\n","   EstimatedSalary  Exited  \n","0        101348.88       1  \n","1        112542.58       0  \n","2        113931.57       1  \n","3         93826.63       0  \n","4         79084.10       0  \n","Logistic Regression Accuracy: 0.8155\n","Random Forest Accuracy: 0.8645\n","Gradient Boosting Accuracy: 0.866\n"]}]}]}